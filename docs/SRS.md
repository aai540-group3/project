# Software Requirements Specification (SRS)

## Document Version

1.7

## Date

September 24, 2024

## Project Name

AAI-540 Final Project - Open Source Machine Learning System

---

## 1. Introduction

### 1.1 Purpose

The purpose of this document is to outline the software requirements for the AAI-540 Final Project, which involves the design, development, and deployment of a production-ready machine learning (ML) system using open-source technologies. This project leverages specific tools and services implemented to deliver a comprehensive ML system, aligning with course requirements while utilizing AWS Free Tier services like S3 for data storage where necessary.

### 1.2 Scope

This project encompasses:

- **Problem Identification**: Addressing hospital readmissions among diabetic patients.
- **Dataset Selection**: Utilizing a publicly available dataset meeting project requirements.
- **System Implementation**: Designing and implementing an end-to-end ML system using specific tools, covering data ingestion, engineering, feature creation, model training, evaluation, deployment, and monitoring.
- **CI/CD Pipelines**: Automating ML workflows using GitHub Actions, with secrets managed via GitHub Secrets.
- **Deployment**: Deploying models using Hugging Face Spaces.
- **Infrastructure Management**: Managing infrastructure as code with Terraform.
- **Documentation**: Documenting the ML system design and operational validation in a comprehensive design document.
- **Demonstration**: Presenting the operational components of the ML system through a video demonstration.
- **Project Management**: Collaboratively managing the project using Asana and maintaining the codebase in a GitHub repository.

### 1.3 Intended Audience

This SRS is intended for:

- **Project Team Members**: To understand system requirements and ensure consistent implementation.
- **Course Instructor**: To evaluate adherence to requirements and grading criteria.
- **Potential Stakeholders**: Interested parties seeking technical insights into the ML system.

---

## 2. Overall Description

### 2.1 Product Perspective

The ML system addresses the problem of predicting 30-day hospital readmissions among diabetic patients. It leverages open-source technologies and adheres to MLOps best practices, ensuring scalability, reliability, and maintainability. The system is developed from scratch and aligns with the course's project scenario and deliverables.

### 2.2 Product Features

The ML system includes the following core features, implemented using specific tools:

- **Data Ingestion and Storage**: Ingesting data from Hugging Face Datasets and storing it in AWS S3 (Free Tier) for processing.
- **Data Engineering**: Performing data cleaning, preprocessing, and transformation using Pandas.
- **Feature Engineering**: Creating new features to enhance model performance using Scikit-learn.
- **Model Training and Evaluation**:
  - Training models using Scikit-learn (Logistic Regression) and AutoGluon (automated model selection).
  - Evaluating model performance using standard metrics and visualizations.
- **Model Registry**: Managing model versions and metadata using DVC and DVC Studio.
- **Model Deployment**: Deploying the trained model as a real-time API endpoint using Hugging Face Spaces.
- **Model Monitoring**: Monitoring model performance over time using DVCLive and DVC Studio, detecting data drift and triggering alerts as needed.
- **CI/CD Pipeline**: Automating building, testing, and deploying ML system components using GitHub Actions, with secrets managed via GitHub Secrets.
- **Infrastructure as Code**: Managing infrastructure using Terraform scripts.
- **Version Control**: Using Git and GitHub for source code management and collaboration.
- **Code Quality and Security**: Implementing code quality checks and security analysis using tools like Codacy.
- **Documentation and Reporting**: Generating reports and documentation, including the ML System Design Document.

### 2.3 User Classes and Characteristics

- **Data Scientists**: Focused on data analysis, feature engineering, and model development.
- **ML Engineers**: Responsible for deploying and maintaining ML system infrastructure, utilizing Terraform.
- **Project Managers**: Use Asana for project planning and tracking team workflows.
- **Business Stakeholders**: Consumers of insights generated by the ML system, requiring interpretable results and reports.

### 2.4 Operating Environment

- **Development Environment**: Local machines or cloud-based environments with necessary tools.
- **Deployment Environment**: Deployed using Hugging Face Spaces.
- **Infrastructure**: Managed with Terraform; data stored in AWS S3 (Free Tier).
- **Operating Systems**: Compatible with Linux, Windows, and macOS.
- **Containers**: Use of Docker where applicable.

### 2.5 Design and Implementation Constraints

- **Project Timeline**: Completion within the AAI-540 course duration.
- **Project Guidelines**: Adherence to course requirements, including deliverables.
- **Programming Language**: Python 3.x for all development.
- **Data Availability**: Use of a publicly available dataset meeting size requirements.
- **Tool Exclusivity**: Exclusive use of implemented tools.
- **Resource Constraints**: Operation within computational resource limitations and free-tier services.

#### 2.5.1 Tools Utilized

The following table lists the specific tools and services used in the ML system. The "Satisfied" column includes a brief statement on how each tool satisfies the project requirements.

| **Component**                             | **Tool Used**                           | **Description**                                                                                                                                     | **Satisfied**                                                                                                                                                                                                                            |
|-------------------------------------------|-----------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Source Control**                        | **GitHub**                              | Hosting Git repositories for version control and collaboration.                                                                                     | Codebase hosted on GitHub; collaborative development facilitated through Git features.                                                                                                             |
| **Data Storage**                          | **AWS S3 (Free Tier)**                  | Scalable cloud storage for data backup and distribution.                                                                                            | Used AWS S3 for storing large data files and managing datasets via DVC remote storage.                                                                                                             |
| **Data Ingestion**                        | **Hugging Face Datasets**               | Access to a wide range of publicly available datasets.                                                                                              | Ingested the diabetic readmission dataset using Hugging Face Datasets API.                                                                                                                         |
| **Data Processing and Engineering**       | **Pandas**                              | Data manipulation and analysis library for Python.                                                                                                  | Employed Pandas for data cleaning, preprocessing, and transformation tasks.                                                                                                                        |
| **Feature Engineering**                   | **Scikit-learn**                        | Machine learning library for Python, used for feature engineering and model development.                                                            | Utilized Scikit-learn for feature scaling, encoding, and creation of polynomial features.                                                                                                          |
| **Model Development**                     | **Scikit-learn, AutoGluon**             | Libraries for machine learning and automated model development.                                                                                     | Trained Logistic Regression model using Scikit-learn and leveraged AutoGluon for automated model training and selection.                                                                            |
| **Experiment Tracking and Model Registry**| **DVC, DVC Studio**                     | Data and model version control, and visual experiment tracking.                                                                                     | Managed datasets and models using DVC; tracked experiments and model versions with DVC Studio.                                                                                                     |
| **CI/CD Pipeline and Automation**         | **GitHub Actions**                      | Automating workflows for building, testing, and deploying code changes; managing secrets via GitHub Secrets.                                        | Implemented automated CI/CD pipelines using GitHub Actions; secrets managed securely with GitHub Secrets.                                                                                          |
| **Model Deployment**                      | **Hugging Face Spaces**                 | Platform for deploying ML models and applications as web apps.                                                                                      | Deployed the trained model as a real-time inference API on Hugging Face Spaces.                                                                                                                    |
| **Infrastructure as Code**                | **Terraform**                           | Tool for building, changing, and versioning infrastructure safely and efficiently.                                                                  | Managed AWS infrastructure components using Terraform scripts for consistent provisioning.                                                                                                          |
| **Model Monitoring**                      | **DVCLive, DVC Studio**                 | Monitoring of data and model performance to detect drift and anomalies.                                                                              | Monitored model metrics during training and evaluation using DVCLive; visualized experiment results in DVC Studio.                                                                                 |
| **Project Management**                    | **Asana**                               | Tool for project planning and tracking team workflows.                                                                                              | Collaborated on project tasks and timelines using Asana boards.                                                                                                                                     |
| **Secrets Management**                    | **GitHub Secrets**                      | Secure storage of sensitive information such as API keys and access tokens within GitHub repositories.                                               | Stored sensitive credentials securely in GitHub Secrets for use in GitHub Actions workflows.                                                                                                       |
| **Code Quality and Security**             | **Codacy, Flake8, Pylint, Bandit**      | Tools for code quality checks and security analysis.                                                                                                | Enforced code quality standards and performed security scanning using Codacy and linters like Flake8 and Pylint; Bandit used for security analysis.                                                |
| **Visualization and Reporting**           | **Matplotlib, Seaborn**                 | Libraries for creating visualizations and reports.                                                                                                  | Generated plots for data analysis and model evaluation metrics using Matplotlib and Seaborn.                                                                                                       |
| **Documentation and Reporting**           | **LaTeX, Markdown**                     | Tools for creating project documentation.                                                                                                           | Produced the ML System Design Document using LaTeX; documentation and README files maintained in Markdown.                                                                                         |

### 2.6 User Documentation

The following user documentation is provided:

- **ML System Design Document**: A comprehensive document detailing the design, implementation, and operational aspects of the ML system.
- **Video Demonstration**: A 10-15 minute presentation demonstrating the ML system's operation.
- **GitHub Repository with README**: Public repository containing the complete codebase, setup instructions, and usage guidelines.

### 2.7 Assumptions and Dependencies

- **Team Skills**: Proficiency in Python and familiarity with the specified tools and practices.
- **Computing Resources**: Access to personal computers or cloud-based services within free-tier limits.
- **Dataset Suitability**: The diabetic readmission dataset is appropriate and meets size requirements.
- **Third-party Libraries**: Reliance on actively maintained libraries and frameworks (e.g., Pandas, Scikit-learn, AutoGluon, DVC).

---

## 3. Specific Requirements

### 3.1 Functional Requirements

| **ID**    | **Feature**                         | **Description**                                                                                                                                          | **Satisfied**                                                                                                                               |
|-----------|-------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|
| **FR-01** | Data Ingestion                      | The system shall ingest data from Hugging Face datasets and store it in AWS S3 for processing.                                                           | Implemented data ingestion using Hugging Face Datasets API; data stored in AWS S3 via DVC remote storage.                                    |
| **FR-02** | Data Preprocessing                  | The system shall perform data cleaning, transformation, normalization, and handling of missing values and outliers using Pandas.                         | Performed data cleaning and preprocessing using Pandas scripts (`cleaning.py`).                                                              |
| **FR-03** | Feature Engineering                 | The system shall create new features from existing data using techniques such as encoding, scaling, and feature extraction with Scikit-learn.            | Implemented feature engineering using Scikit-learn in `build_features.py`, including polynomial features and scaling.                        |
| **FR-04** | Model Training                      | The system shall train ML models using Scikit-learn and AutoGluon, supporting hyperparameter tuning and model selection as appropriate.                  | Trained Logistic Regression model with Scikit-learn and automated model training with AutoGluon.                                             |
| **FR-05** | Model Evaluation                    | The system shall evaluate model performance using relevant metrics and generate evaluation reports and visualizations.                                   | Evaluated models using standard metrics; generated reports and plots (ROC curve, confusion matrix) using Matplotlib and Seaborn.             |
| **FR-06** | Model Registry                      | The system shall manage trained models and their versions using DVC and DVC Studio, tracking metadata and performance metrics.                           | Managed model versions and tracked experiments using DVC and DVC Studio.                                                                     |
| **FR-07** | CI/CD Pipeline                      | The system shall implement an automated CI/CD pipeline for building, testing, and deploying ML system components upon code changes using GitHub Actions. | Configured GitHub Actions workflows for automated testing, building, and deployment upon code changes.                                        |
| **FR-08** | Secrets Management                  | The system shall manage sensitive information using GitHub Secrets to ensure secure handling of credentials and access tokens.                           | Stored API keys and sensitive data in GitHub Secrets for secure access during CI/CD processes.                                                |
| **FR-09** | Model Deployment                    | The system shall deploy trained models as real-time API endpoints accessible via Hugging Face Spaces.                                                    | Deployed the model as a RESTful API on Hugging Face Spaces for real-time inference.                                                          |
| **FR-10** | Model Monitoring                    | The system shall monitor model performance over time using DVCLive and DVC Studio, detecting issues like data drift and triggering alerts as needed.     | Monitored training and evaluation metrics using DVCLive; visualized experiment history in DVC Studio.                                         |
| **FR-11** | Infrastructure as Code              | The system shall manage and provision infrastructure using Terraform scripts to ensure consistent environments.                                          | Developed Terraform scripts to provision AWS resources consistently.                                                                          |
| **FR-12** | Version Control                     | The system shall use Git and GitHub for source code management and collaboration among team members.                                                     | All code and documentation managed via Git and hosted on GitHub; collaborative development ensured through version control.                  |
| **FR-13** | Logging and Tracing                 | The system shall implement logging mechanisms to debug issues and trace data flow through the system using standard Python logging.                       | Implemented logging in all scripts using Python's logging module for debugging and tracing.                                                   |
| **FR-14** | Security and Access Control         | The system shall implement security measures to protect data and models, including authentication and authorization mechanisms as needed.                | Ensured data protection by managing access via GitHub Secrets and AWS IAM roles; sensitive data handled securely.                             |
| **FR-15** | Code Quality and Security Analysis  | The system shall enforce code quality standards and perform security analysis using tools like Codacy, Flake8, Pylint, and Bandit.                       | Configured Codacy for continuous code quality checks; used Flake8, Pylint, and Bandit for linting and security analysis.                      |
| **FR-16** | Documentation Generation            | The system shall generate documentation and reports automatically where possible, integrating with project requirements like the Design Document.        | Generated the ML System Design Document using automated LaTeX scripts; documentation updated alongside codebase changes.                     |

### 3.2 Non-Functional Requirements

| **ID**     | **Type**           | **Description**                                                                                                                                    | **Satisfied**                                                                                                                           |
|------------|--------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|
| **NFR-01** | Performance        | The system shall process data and generate predictions within acceptable timeframes suitable for application needs.                                 | Models optimized for performance; acceptable inference times achieved in deployment.                                                    |
| **NFR-02** | Scalability        | The system shall be designed to handle increasing data volumes by leveraging scalable services like AWS S3 and Hugging Face Spaces.                | Data storage and deployment services selected for scalability; infrastructure can handle increased loads.                                |
| **NFR-03** | Reliability        | The system shall have minimal downtime and be resilient to failures, ensuring consistent availability.                                             | Reliance on reliable cloud services; CI/CD pipelines ensure consistent deployments.                                                     |
| **NFR-04** | Security           | The system shall protect sensitive data and models from unauthorized access, utilizing GitHub Secrets and adhering to data protection standards.    | Implemented security best practices; credentials secured; data access controlled via IAM policies.                                       |
| **NFR-05** | Maintainability    | The system shall be modular and well-documented, allowing for easy updates, maintenance, and onboarding of new team members.                        | Modular code structure; comprehensive documentation provided; code adheres to standards for maintainability.                             |
| **NFR-06** | Usability          | The system shall provide intuitive interfaces and clear documentation for users and developers.                                                    | User-friendly deployment on Hugging Face Spaces; documentation guides users and developers effectively.                                  |
| **NFR-07** | Portability        | The system shall be deployable on various platforms with minimal configuration changes, facilitated by Docker containerization where applicable.    | Codebase designed for portability; dependencies managed; Docker used where necessary.                                                    |
| **NFR-08** | Compliance         | The system shall comply with relevant legal and regulatory requirements, such as data privacy laws.                                                 | Ensured compliance with data usage and privacy regulations; data anonymized as required.                                                 |
| **NFR-09** | Code Quality       | The system shall adhere to code quality standards and best practices, ensuring readability and maintainability.                                     | Code formatted according to standards; code quality enforced through linters and continuous integration.                                 |
| **NFR-10** | Automated Testing  | The system shall include automated tests to verify the correctness of the codebase and detect regressions.                                          | Implemented automated testing routines; tests integrated into CI/CD pipelines to detect issues promptly.                                 |

---

## 4. Future Enhancements

Potential future enhancements include:

- Incorporating advanced modeling techniques, such as deep learning models.
- Implementing AutoML tools to further automate model selection and hyperparameter tuning.
- Developing a user-friendly interface beyond Hugging Face Spaces.
- Integrating explainability tools like SHAP or LIME.
- Enabling continuous learning capabilities for model updates.
- Exploring edge deployment for on-device inference.
- Implementing comprehensive monitoring with tools like Prometheus and Grafana.

---

## 5. Appendices

### Appendix A: Glossary of Terms

- **ML (Machine Learning)**: Techniques enabling systems to learn from data.
- **MLOps**: Practices combining ML, DevOps, and data engineering for reliable ML system deployment.
- **CI/CD (Continuous Integration/Continuous Deployment)**: Automating code integration, testing, and deployment.
- **API (Application Programming Interface)**: Protocols for building and interacting with software applications.
- **DVC (Data Version Control)**: Tool for data and model versioning.
- **Terraform**: Infrastructure-as-code tool for managing infrastructure.
- **Hugging Face Spaces**: Platform to host ML demos and applications.
- **DVCLive**: Library for logging ML experiment data.

### Appendix B: List of Abbreviations

- **SRS**: Software Requirements Specification
- **ML**: Machine Learning
- **MLOps**: Machine Learning Operations
- **CI/CD**: Continuous Integration/Continuous Deployment
- **API**: Application Programming Interface
- **DVC**: Data Version Control
- **DVCLive**: DVC Live Logging Library

### Appendix C: References

- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [AutoGluon Documentation](https://auto.gluon.ai/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Hydra Documentation](https://hydra.cc/docs/intro/)
- [DVC Documentation](https://dvc.org/doc)
- [DVC Studio](https://studio.iterative.ai/)
- [Hugging Face Datasets](https://huggingface.co/datasets/)
- [Hugging Face Spaces](https://huggingface.co/spaces)
- [GitHub Actions](https://github.com/features/actions)
- [GitHub Secrets Documentation](https://docs.github.com/en/actions/security-guides/encrypted-secrets)
- [Terraform Documentation](https://www.terraform.io/docs/)
- [DVCLive Documentation](https://dvc.org/doc/dvclive)
- [Asana](https://asana.com/)
- [AWS S3 Free Tier](https://aws.amazon.com/free/)
- [Codacy](https://www.codacy.com/)
