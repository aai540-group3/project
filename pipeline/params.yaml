---
#-----------------------------------------------------------------------------#
# GLOBAL SETTINGS
#-----------------------------------------------------------------------------#
project: diabetes_readmission
version: 0.1.0
mode: full
seed: 42

#-----------------------------------------------------------------------------#
# PATHS
#-----------------------------------------------------------------------------#
paths:
  raw: data/raw
  interim: data/interim
  processed: data/processed
  feature_repo: feature_repo
  metrics: metrics
  plots: plots
  models: models

#-----------------------------------------------------------------------------#
# AWS CONFIGURATION
#-----------------------------------------------------------------------------#
aws:
  bucket_name: aai540-group3
  region: us-east-1

#-----------------------------------------------------------------------------#
# FEAST
#-----------------------------------------------------------------------------#
feast:
  stop_container: false
  config:
    project: diabetes_readmission
    provider: local
    registry:
      registry_type: sql
      path: postgresql+psycopg://feast:feast@localhost:5432/feast
      cache_ttl_seconds: 600
      sqlalchemy_config_kwargs:
        echo: false
        pool_pre_ping: true
    offline_store:
      type: postgres
      host: localhost
      port: 5432
      database: feast
      db_schema: public
      user: feast
      password: feast
    online_store:
      type: postgres
      host: localhost
      port: 5432
      database: feast
      db_schema: feature_store
      user: feast
      password: feast
    entity_key_serialization_version: 2
    coerce_tz_aware: true

#-----------------------------------------------------------------------------#
# DATASET CONFIGURATION
#-----------------------------------------------------------------------------#
dataset:
  name: "Diabetes 130-US Hospitals for Years 1999-2008"
  id: 296
  source: ucimlrepo
  timestamp: "1999-01-01T00:00:00+00:00"
  splits:
    train: 0.80
    test: 0.10
    val: 0.10

#-----------------------------------------------------------------------------#
# BASE MODEL CONFIGURATION
#-----------------------------------------------------------------------------#
models:
  base:
    quick:
      sample_fraction: 0.1
    full:
      sample_fraction: 1.0
    label: readmitted
    metric: roc_auc
    problem_type: binary

  #-----------------------------------------------------------------------------#
  # MODEL: AutoGluon
  #-----------------------------------------------------------------------------#
  autogluon:
    quick:
      time_limit: 60
      presets: medium_quality
      hyperparameters:
        NN_TORCH:
          num_epochs: 1
    full:
      time_limit: 7200
      presets: best_quality
      hyperparameters:
        GBM:
          extra_trees: true
          learning_rate: 0.05
          num_boost_round: 500
          num_leaves: 128
          feature_fraction: 0.8
          min_data_in_leaf: 20
        CAT:
          iterations: 1000
          depth: 8
          learning_rate: 0.05
          min_data_in_leaf: 20
        XGB:
          max_depth: 8
          learning_rate: 0.05
          n_estimators: 500
          subsample: 0.8
          colsample_bytree: 0.8

  #-----------------------------------------------------------------------------#
  # MODEL: Logistic Regression
  #-----------------------------------------------------------------------------#
  logisticregression:
    quick:
      model_params: {}
      training:
        optimizer:
          name: adam
          params:
            lr: 0.01
        loss: binary_cross_entropy
        batch_size: 32
        epochs: 1
    full:
      model_params: {}
      training:
        optimizer:
          name: adam
          params:
            lr: 0.001
        loss: binary_cross_entropy
        batch_size: 64
        epochs: 50

  #-----------------------------------------------------------------------------#
  # MODEL: Neural Network
  #-----------------------------------------------------------------------------#
  neuralnetwork:
    quick:
      model_params: {}
      training:
        optimizer:
          name: adam
          params:
            lr: 0.001
        loss: binary_cross_entropy
        metrics:
          - accuracy
          - AUC
        batch_size: 32
        epochs: 10
        class_weight: balanced
        callbacks:
          early_stopping:
            enabled: true
            params:
              monitor: val_loss
              patience: 2
              restore_best_weights: true
          model_checkpoint:
            enabled: false
          tensorboard:
            enabled: false
      architecture:
        input_layer:
          batch_norm: true
          dropout: 0.0
        hidden_layers:
          - units: 64
            activation: relu
            batch_norm: true
            dropout: 0.4
          - units: 32
            activation: relu
            batch_norm: true
            dropout: 0.3
        output_layer:
          units: 1
          activation: None

    full:
      model_params: {}
      training:
        optimizer:
          name: adam
          params:
            lr: 0.0005
        loss: binary_cross_entropy
        metrics:
          - accuracy
          - AUC
        batch_size: 64
        epochs: 50
        class_weight: balanced
        callbacks:
          early_stopping:
            enabled: true
            params:
              monitor: val_loss
              patience: 5
              restore_best_weights: true
          model_checkpoint:
            enabled: true
            params:
              monitor: val_loss
              save_best_only: true
              mode: min
          tensorboard:
            enabled: true
            params:
              histogram_freq: 1
              write_graph: true
              write_images: true
      architecture:
        input_layer:
          batch_norm: true
          dropout: 0.0
        hidden_layers:
          - units: 128
            activation: relu
            batch_norm: true
            dropout: 0.3
            kernel_regularizer:
              name: l2
              params:
                l2: 0.001
          - units: 64
            activation: relu
            batch_norm: true
            dropout: 0.3
            kernel_regularizer:
              name: l2
              params:
                l2: 0.001
          - units: 32
            activation: relu
            batch_norm: true
            dropout: 0.3
            kernel_regularizer:
              name: l2
              params:
                l2: 0.001
        output_layer:
          units: 1
          activation: None

#-----------------------------------------------------------------------------#
# VISUALIZATION CONFIGURATION
#-----------------------------------------------------------------------------#
visualization:
  style: "seaborn-v0_8-white"
  palette: "viridis"
  theme:
    style: "white"
    context: "paper"
    font_scale: 1.6
    rc:
      # Core settings
      figure.dpi: 300
      savefig.dpi: 300
      figure.figsize: [10, 6.18] # Golden ratio
      figure.facecolor: "white"
      figure.autolayout: true
      # Typography
      font.family: ["Fira Sans", "Helvetica Neue", "Arial", "sans-serif"]
      axes.labelsize: 13
      axes.titlesize: 15
      axes.labelweight: "regular"
      xtick.labelsize: 11
      ytick.labelsize: 11
      # Axes Styling
      axes.spines.top: false
      axes.spines.right: false
      axes.spines.left: true
      axes.spines.bottom: true
      axes.linewidth: 0.8
      axes.axisbelow: true
      # Grid styling
      grid.linestyle: ":"
      grid.alpha: 0.15
      grid.color: "#666666"
      # Legend Styling
      legend.fontsize: 11
      legend.frameon: false
      legend.borderaxespad: 0.5
      # Colors
      axes.prop_cycle.color:
        [
          "#0077BB",
          "#EE7733",
          "#009988",
          "#EE3377",
          "#CC3311",
          "#33BBEE",
          "#BB5566",
        ]
