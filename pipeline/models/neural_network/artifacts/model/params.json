{
    "n_layers": 2,
    "units_first": 48,
    "units_factor": 0.7950714306409916,
    "dropout": 0.2731993941811405,
    "learning_rate": 0.003968793330444372,
    "batch_size": 32,
    "activation": "relu",
    "optimizer": "adam"
}