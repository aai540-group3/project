---
#-------------------------------------------------------------------------------
# DEFAULTS
#-------------------------------------------------------------------------------
defaults:
  - override hydra/hydra_logging: colorlog
  - override hydra/job_logging: colorlog

#-------------------------------------------------------------------------------
# HYDRA
#-------------------------------------------------------------------------------
hydra:
  # Enable chdir to allow relative paths to work correctly
  job:
    chdir: true
  # Set the output directory for the experiment
  run:
    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  # Enable verbose logging
  verbose: true

#-------------------------------------------------------------------------------
# GLOBALS
#-------------------------------------------------------------------------------
# Set the random seed for reproducibility
seed: 42

#-------------------------------------------------------------------------------
# LOGGING
#-------------------------------------------------------------------------------
logging:
  enabled: true
  level: INFO
  console:
    enabled: true
    level: DEBUG
    format: "<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>"
    colored: true
    use_rich: true
  file:
    enabled: true
    level: INFO
    path: "${paths.logs}/pipeline.log"
    format: "{time:YYYY-MM-DD HH:mm:ss} | {level} | {name}:{function}:{line} - {message}"
    rotation: "1 day" # Rotate logs daily
    retention: "7 days" # Keep logs for 7 days
    compression: "zip" # Compress rotated logs
  loggers:
    pipeline.utils.logging:
      level: DEBUG

#-------------------------------------------------------------------------------
# PATHS
#-------------------------------------------------------------------------------
paths:
  root: ${hydra:runtime.cwd}
  logs: ${paths.root}/logs
  # DATA
  data: ${paths.root}/data
  processed: ${paths.data}/processed
  interim: ${paths.data}/interim
  raw: ${paths.data}/raw
  # OUTPUTS
  artifacts: ${paths.root}/artifacts
  metrics: ${paths.root}/metrics
  models: ${paths.root}/models
  plots: ${paths.root}/plots
  # PIPELINE
  infrastruct: ${paths.root}/infrastruct
  features: ${paths.data}/features
  registry: ${paths.root}/registry
  deploy: ${paths.root}/deploy

#-------------------------------------------------------------------------------
# DATA
#-------------------------------------------------------------------------------
data:
  # Define the target column for the prediction task
  target_column: readmitted
  # Define the paths to the processed data files
  test_path: ${paths.processed}/test_features.parquet
  train_path: ${paths.processed}/train_features.parquet
  val_path: ${paths.processed}/val_features.parquet
  # Define the data sources
  sources:
    - type: uci
      dataset_id: 296
      name: "Diabetes 130-US hospitals"
      required: true
      version: "1.0.0"

  #-------------------------------------------------------------------------------
  # Preprocessing Configuration
  #-------------------------------------------------------------------------------
  preprocessing:
    # Define the columns to drop
    drop_columns:
      - weight
      - payer_code
      - medical_specialty
      - citoglipton
      - examide

    # Define the missing value handling strategy
    missing_values:
      numeric: median # Options: 'mean', 'median', etc.
      categorical: mode # Options: 'mode', 'constant', etc.
      fill_value: unknown # Used if strategy is 'constant'

    # Define duplicate handling settings
    duplicate_subset:
      - patient_nbr # Column(s) to check for duplicates
    duplicate_keep: first # Options: first, last, False (drop all duplicates)

    # Define conditions to filter out invalid entries
    invalid_conditions:
      - discharge_disposition_id != 11 # Remove patients who expired during the encounter

    # Define mappings for categorical variables
    binary_mappings:
      gender:
        Male: 1
        Female: 0
      change:
        Ch: 1
        No: 0
      diabetesmed:
        Yes: 1
        No: 0

    ordinal_mappings:
      age:
        "[0-10)": 5
        "[10-20)": 15
        "[20-30)": 25
        "[30-40)": 35
        "[40-50)": 45
        "[50-60)": 55
        "[60-70)": 65
        "[70-80)": 75
        "[80-90)": 85
        "[90-100)": 95

    # Medication columns to encode
    medication_columns:
      - metformin
      - repaglinide
      - nateglinide
      - chlorpropamide
      - glimepiride
      - glipizide
      - glyburide
      - pioglitazone
      - rosiglitazone
      - acarbose
      - miglitol
      - insulin
      - glyburide-metformin
      - tolazamide
      - metformin-pioglitazone
      - metformin-rosiglitazone
      - glimepiride-pioglitazone
      - glipizide-metformin
      - troglitazone
      - tolbutamide
      - acetohexamide

    # Lab result mappings
    lab_mappings:
      a1cresult:
        ">7": 1
        ">8": 1
        "Norm": 0
        "None": -99
      max_glu_serum:
        ">200": 1
        ">300": 1
        "Norm": 0
        "None": -99

    # Other categorical mappings
    other_mappings:
      admission_type_id:
        2: 1
        7: 1
        6: 5
        8: 5
      discharge_disposition_id:
        6: 1
        8: 1
        9: 1
        13: 1 # Home
        3: 2
        4: 2
        5: 2
        14: 2
        22: 2
        23: 2
        24: 2 # Healthcare Facility
        12: 10
        15: 10
        16: 10
        17: 10 # Outpatient
        25: 18
        26: 18 # Psychiatric
      admission_source_id:
        2: 1
        3: 1 # Physician Referral
        5: 4
        6: 4
        10: 4
        22: 4
        25: 4 # Transfer
        15: 9
        17: 9
        20: 9
        21: 9 # Emergency
        13: 11
        14: 11 # Other

    # Define the outlier handling settings
    outlier_handling:
      enabled: true
      method: iqr
      iqr_multiplier: 1.5
      exclude_columns:
        - readmitted
        - id
        - patient_nbr
        - encounter_id
      # Optionally specify columns to include
      # columns:
      #   - time_in_hospital
      #   - num_lab_procedures
      #   - num_procedures
      #   - num_medications
      #   - number_outpatient
      #   - number_emergency
      #   - number_inpatient
      #   - number_diagnoses

    # Define the target mapping
    target_mapping:
      NO: 0
      ">30": 1
      "<30": 1

    # Specify the target column
    target_column: readmitted

    # Define the diagnosis columns
    diagnosis_columns:
      - diag_1
      - diag_2
      - diag_3

    # Specify paths for saving processed data
    processed_data_path: ${paths.interim}/data_cleaned.parquet
    feature_names_path: ${paths.interim}/feature_names.csv

#-------------------------------------------------------------------------------
# SPLITS
#-------------------------------------------------------------------------------
splits:
  # Set the random state for splitting the data
  random_state: ${seed}
  # Enable stratified splitting based on the target column
  stratify: true
  # Set the size of the test set
  test_size: 0.2
  # Set the size of the validation set
  val_size: 0.2

#-------------------------------------------------------------------------------
# TRAINING
#-------------------------------------------------------------------------------
training:
  # Set the batch size for training
  batch_size: 32
  # Set the early stopping parameters
  early_stopping:
    enabled: true
    min_delta: 0.001
    mode: min
    monitor: val_loss
    patience: 10
  # Set the number of epochs for training
  epochs: 100
  # Set the training metrics
  metrics:
    - accuracy
    - precision
    - recall
    - f1
    - roc_auc
  # Set the optimizer parameters
  optimizer:
    learning_rate: 0.001
    name: adam
  # Set the random seed for training
  seed: ${seed}

#-------------------------------------------------------------------------------
# MODEL
#-------------------------------------------------------------------------------
model:
  # Define the logistic regression model parameters
  logistic:
    enabled: true
    C: 1.0
    class_weight: balanced
    max_iter: 1000
    multi_class: ovr
    n_jobs: -1
    penalty: l2
    random_state: ${training.seed}
    solver: lbfgs
  # Define the neural network model architecture
  neural:
    enabled: true
    architecture:
      input_layer:
        batch_norm: true
        dropout: 0.1
      hidden_layers:
        - activation: relu
          batch_norm: true
          dropout: 0.3
          units: 128
        - activation: relu
          batch_norm: true
          dropout: 0.2
          units: 64
        - activation: relu
          batch_norm: true
          dropout: 0.1
          units: 32
      output_layer:
        activation: sigmoid
        units: 1
  # Define the AutoGluon model parameters
  autogluon:
    enabled: true
    label: ${data.target_column}
    problem_type: binary
    eval_metric: roc_auc
    verbosity: 2

#-------------------------------------------------------------------------------
# FEATURES
#-------------------------------------------------------------------------------
features:
  # Define the binary features
  binary_features:
    - change
    - diabetesmed
  # Define the categorical features
  categorical_features:
    - race
    - gender
    - admission_type_id
    - discharge_disposition_id
    - admission_source_id
  # Enable domain-specific features
  domain_specific: true
  # Enable feature interactions
  interactions: true
  # Define the numeric features
  numeric_features:
    - age
    - time_in_hospital
    - num_lab_procedures
    - num_procedures
    - num_medications
    - number_outpatient
    - number_emergency
    - number_inpatient
    - number_diagnoses
  # Disable polynomial features
  polynomial: false

#-------------------------------------------------------------------------------
# EVALUATION
#-------------------------------------------------------------------------------
evaluation:
  # Define the feature importance settings
  feature_importance:
    top_n: 10
  # Define the evaluation metrics
  metrics:
    - accuracy
    - precision
    - recall
    - f1
    - roc_auc

#-------------------------------------------------------------------------------
# EXPERIMENT
#-------------------------------------------------------------------------------
experiment:
  # Set the experiment description
  description: Quick training for pipeline validation
  # Set the experiment name
  name: quick
  # Define the experiment registry settings
  registry:
    enabled: true
    model_name: ${experiment.name}-${model.name}
    selection_metric: roc_auc
    selection_threshold: 0.8
    uri: ${mlflow.tracking_uri}
  # Define the experiment tags
  tags:
    - dev
    - quick
  # Define the experiment tracking settings
  tracking:
    # Enable DVC tracking
    dvc:
      enabled: true
    # Enable MLflow tracking
    mlflow:
      enabled: true
    # Enable Weights & Biases tracking
    wandb:
      enabled: true
      infrastruct:
        log_costs: false
        log_modifications: true
        log_resources: true

#-------------------------------------------------------------------------------
# MLFLOW
#-------------------------------------------------------------------------------
mlflow:
  # Enable MLflow tracking
  enabled: true
  # Set the experiment name for MLflow
  experiment_name: ${experiment.name}
  # Set the MLflow tracking URI
  tracking_uri: file:///tmp/mlruns

#-------------------------------------------------------------------------------
# WANDB
#-------------------------------------------------------------------------------
wandb:
  # Enable Weights & Biases tracking
  enabled: true
  # Set the Weights & Biases entity
  entity: aai540-group3
  # Set the Weights & Biases project
  project: aai540-group3
  # Set the Weights & Biases mode
  mode: offline
  # Define the Weights & Biases tags
  tags: []
  # Define the Weights & Biases visualizations settings
  visualizations:
    infrastruct:
      enabled: true
      charts:
        - name: AWS Resource Status
          type: resource_status
        - name: Resource Creation Times
          type: creation_times
        - name: Resource Errors
          type: error_tracking

#-------------------------------------------------------------------------------
# OPTIMIZATION
#-------------------------------------------------------------------------------
optimize:
  # Set the optimization direction
  direction: maximize
  # Set the optimization metric
  metric: roc_auc
  # Set the number of optimization trials
  n_trials: 100
  # Define the parameter space for optimization
  param_space:
    C:
      type: float
      low: 1e-4
      high: 1e4
      log: true
    penalty:
      type: categorical
      choices:
        - l1
        - l2
        - elasticnet
    solver:
      type: categorical
      choices:
        - saga
        - liblinear
    l1_ratio:
      type: float
      low: 0.0
      high: 1.0
      condition: params.penalty == 'elasticnet'
  # Set the optimization timeout
  timeout: 3600

#-------------------------------------------------------------------------------
# OPTIMIZER
#-------------------------------------------------------------------------------
optimizer:
  # Set the optimizer parameters
  name: adam
  learning_rate: 0.001
  beta_1: 0.9
  beta_2: 0.999
  epsilon: 1e-07

#-------------------------------------------------------------------------------
# ALERTING
#-------------------------------------------------------------------------------
alerting:
  # Define the email alerting settings
  email:
    enabled: false
    recipients: null
  # Define the Slack alerting settings
  slack:
    enabled: false
    webhook_url: null

#-------------------------------------------------------------------------------
# API
#-------------------------------------------------------------------------------
api:
  # Define the CORS settings
  cors:
    enabled: true
    allow_origins:
      - "*"
    allow_methods:
      - GET
      - POST
    allow_headers:
      - "*"
  # Define the API host
  host: 0.0.0.0
  # Define the API port
  port: 8000
  # Define the API timeout
  timeout: 30
  # Define the number of API workers
  workers: 4

#-------------------------------------------------------------------------------
# AWS
#-------------------------------------------------------------------------------
aws:
  # Define the AWS profile to use
  profile: default
  # Define the AWS region to use
  region: us-east-1
  # Define the AWS Cloudwatch settings
  cloudwatch:
    enabled: true
    dashboards:
      enabled: true
      refresh_interval: 300
    log_retention_days: 30
    metrics:
      - name: ResourceCreationSuccess
        threshold: 1
        unit: Count
      - name: ResourceCreationLatency
        threshold: 300
        unit: Seconds
      - name: ResourceErrors
        threshold: 0
        unit: Count
  # Define the AWS DynamoDB settings
  dynamodb:
    table:
      name: aai540-group3
      hash_key: id
      billing_mode: PAY_PER_REQUEST
      encryption:
        enabled: true
      backup:
        enabled: true
        retention_days: 7
      monitoring:
        enabled: true
        metrics:
          - ReadCapacityUtilization
          - WriteCapacityUtilization
          - ThrottledRequests
      tags:
        DataClass: Production
        Purpose: FeatureStore
  # Define the AWS S3 settings
  s3:
    bucket:
      name: aai540-group3
      versioning: enabled
      encryption:
        enabled: true
        type: AES256
      logging:
        enabled: true
        track_access: true
      lifecycle_rules:
        - enabled: true
          prefix: logs/
          expiration_days: 90
      tags:
        DataClass: Experimental
        Purpose: MLArtifacts

  # Define the AWS monitoring settings
  monitoring:
    enabled: false
    namespace: aai540-group3
    metrics: []
    alerts:
      enabled: false
      sns_topic: null
  # Define the AWS tags
  tags:
    Environment: dev
    ManagedBy: MLOps-Pipeline
    Project: DiabetesReadmission

#-------------------------------------------------------------------------------
# CALLBACKS
#-------------------------------------------------------------------------------
callbacks:
  # Define the early stopping callback settings
  early_stopping:
    enabled: true
    monitor: val_loss
    patience: 10
    min_delta: 0.001
    mode: min
    restore_best_weights: true
  # Define the model checkpoint callback settings
  model_checkpoint:
    enabled: true
    monitor: val_loss
    filepath: ${paths.models}/${model.name}/checkpoints/best_model.h5
    save_best_only: true
    mode: min

#-------------------------------------------------------------------------------
# DVC
#-------------------------------------------------------------------------------
dvc:
  enabled: ${experiment.tracking.dvc.enabled}
  region: us-east-1
  autostage: true
  auto_push: true
  analytics: false
  remote:
    - name: dvcstore
      url: s3://aai540-group3/dvcstore
  studio: https://studio.iterative.ai

#-------------------------------------------------------------------------------
# HUGGINGFACE
#-------------------------------------------------------------------------------
huggingface:
  repo_id: diabetes-readmission-risk-prediction
  private: false
  token: ${env:HF_TOKEN}

#-------------------------------------------------------------------------------
# MONITORING
#-------------------------------------------------------------------------------
monitoring:
  enabled: true
  interval: 60
  metrics:
    - name: accuracy
      threshold: 0.75
      type: model
    - name: roc_auc
      threshold: 0.8
      type: model
    - name: feature_drift
      threshold: 0.1
      type: drift
  infrastruct:
    enabled: true
    alerts:
      enabled: true
      channels:
        - type: slack
          webhook: https://your.slack.webhook.url
        - recipients: alert@example.com
          type: email
    thresholds:
      setup_time_seconds: 300
      max_errors: 0
      resource_creation_attempts: 3

#-------------------------------------------------------------------------------
# INFRASTRUCT
#-------------------------------------------------------------------------------
infrastruct:
  enabled: true
  logging:
    level: DEBUG
    resources:
      track_tags: true
      track_policies: true
      track_modifications: true
      track_creation_time: true
  params:
    - aws
    - paths
  deps:
    - pipeline/stages/infrastruct.py
  tracking:
    enabled: true
    mlflow:
      enabled: false
    wandb:
      enabled: true
      tags:
        - infrastruct

#-------------------------------------------------------------------------------
# EXPLORE
#-------------------------------------------------------------------------------
explore:
  target_column: ${data.target_column}
  correlation_threshold: 0.8
  n_top_features: 20

#-------------------------------------------------------------------------------
# PIPELINE
#-------------------------------------------------------------------------------
pipeline:
  stages:
    # Define the ingest stage
    ingest:
      enabled: true
      deps:
        - pipeline/stages/ingest.py
        - conf/data/sources.yaml
      params:
        - data.sources
        - paths
      tracking:
        enabled: false
    # Define the preprocess stage
    preprocess:
      enabled: true
      deps:
        - pipeline/stages/preprocess.py
        - data/raw/data.csv
      params:
        - data.preprocessing
        - data.splits
        - paths
      tracking:
        enabled: false
    # Define the featurize stage
    featurize:
      enabled: true
      deps:
        - pipeline/stages/featurize.py
        - data/interim/train.parquet
        - data/interim/val.parquet
        - data/interim/test.parquet
      params:
        - features
        - paths
      tracking:
        enabled: true
        mlflow:
          enabled: true
        wandb:
          enabled: true
    # Define the explore stage
    explore:
      enabled: true
      deps:
        - pipeline/stages/explore.py
        - data/raw/data.csv
        - data/interim/data_cleaned.parquet
      params:
        - explore
        - paths
      tracking:
        enabled: true
        mlflow:
          enabled: false
        wandb:
          enabled: true
    # Define the train stage
    train:
      enabled: true
      do:
        deps:
          - pipeline/stages/train.py
          - pipeline/models/${item}.py
        params:
          - model.${item}
          - training
          - paths
      foreach: ${model_types}
      tracking:
        enabled: true
        mlflow:
          enabled: true
        wandb:
          enabled: true
    # Define the evaluate stage
    evaluate:
      enabled: true
      deps:
        - pipeline/stages/evaluate.py
      params:
        - evaluation
        - paths
      tracking:
        enabled: true
        mlflow:
          enabled: true
        wandb:
          enabled: true
    # Define the optimize stage
    optimize:
      enabled: true
      do:
        deps:
          - pipeline/stages/optimize.py
          - pipeline/models/${item}.py
        params:
          - model.${item}
          - optimize
          - paths
      foreach: ${model_types}
      tracking:
        enabled: true
        mlflow:
          enabled: true
        wandb:
          enabled: true
    # Define the register stage
    register:
      enabled: true
      deps:
        - pipeline/stages/register.py
      params:
        - registry
        - paths
      tracking:
        enabled: true
        mlflow:
          enabled: true
        wandb:
          enabled: false
    # Define the deploy stage
    deploy:
      enabled: true
      deps:
        - pipeline/stages/deploy.py
      params:
        - huggingface
        - paths
      tracking:
        enabled: true
        mlflow:
          enabled: false
        wandb:
          enabled: true
    # Define the infrastruct stage
    infrastruct:
      enabled: true
      deps:
        - pipeline/stages/infrastruct.py
        - conf/infrastructure/aws.yaml
      params:
        - aws
        - paths
      tracking:
        enabled: false

#-------------------------------------------------------------------------------
# SERVICES
#-------------------------------------------------------------------------------
services:
  # Define the Feast service settings
  feast:
    enabled: false
    project: ${env:FEAST_PROJECT}
    registry_path: ${env:FEAST_REGISTRY}
    online_store:
      table_name: ${env:FEAST_TABLE_NAME}
